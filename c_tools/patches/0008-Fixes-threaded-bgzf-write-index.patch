From e9863a0f149ea4d9e4336a061d7437952b6c7c8e Mon Sep 17 00:00:00 2001
From: James Bonfield <jkb@sanger.ac.uk>
Date: Wed, 19 Feb 2020 11:23:33 +0000
Subject: [PATCH 08/10] Fixes threaded bgzf --write-index.

This adds the analogue of the hts_idx_amend_last function for bgzf.
This is necessary when multi-threading output using --write-index.

Fixes samtools/samtools#1197

In theory the change should have no impact as the only difference is
whether our virtual offset points to the end of a block or the start
of the next block.  Either way the two offsets are essentially the
same locaiton on disk.  However due to a bug elsewhere (see next
commit) this lead to unreported bgzf_read failures.
---
 bgzf.c         | 34 ++++++++++++++++++++++++++++++++++
 hts_internal.h | 12 ++++++++++++
 sam.c          |  2 ++
 3 files changed, 48 insertions(+)

diff --git a/bgzf.c b/bgzf.c
index 0a76676..f2e9b1e 100644
--- a/bgzf.c
+++ b/bgzf.c
@@ -226,6 +226,40 @@ int bgzf_idx_push(BGZF *fp, hts_idx_t *hidx, int tid, hts_pos_t beg, hts_pos_t e
     return 0;
 }
 
+/*
+ * bgzf analogue to hts_idx_amend_last.
+ *
+ * This is needed when multi-threading and writing indices on the fly.
+ * At the point of writing a record we know the virtual offset for start
+ * and end, but that end virtual offset may be the end of the current
+ * block.  In standard indexing our end virtual offset becomes the start
+ * of the next block.  Thus to ensure bit for bit compatibility we
+ * detect this boundary case and fix it up here.
+ *
+ * In theory this has no behavioural change, but it also works around
+ * a bug elsewhere which causes bgzf_read to return 0 when our offset
+ * is the end of a block rather than the start of the next.
+ */
+void bgzf_idx_amend_last(BGZF *fp, hts_idx_t *hidx, uint64_t offset) {
+    mtaux_t *mt = fp->mt;
+    if (!mt) {
+        hts_idx_amend_last(hidx, offset);
+        return;
+    }
+
+    pthread_mutex_lock(&mt->idx_m);
+    hts_idx_cache_t *ic = &mt->idx_cache;
+    if (ic->nentries > 0) {
+        hts_idx_cache_entry *e = &ic->e[ic->nentries-1];
+        if ((offset & 0xffff) == 0 && e->offset != 0) {
+            // bumped to next block number
+            e->offset = 0;
+            e->block_number++;
+        }
+    }
+    pthread_mutex_unlock(&mt->idx_m);
+}
+
 static int bgzf_idx_flush(BGZF *fp) {
     mtaux_t *mt = fp->mt;
 
diff --git a/hts_internal.h b/hts_internal.h
index dad04cb..2708123 100644
--- a/hts_internal.h
+++ b/hts_internal.h
@@ -108,6 +108,18 @@ void close_plugin(void *plugin);
  */
 int bgzf_idx_push(BGZF *fp, hts_idx_t *hidx, int tid, hts_pos_t beg, hts_pos_t end, uint64_t offset, int is_mapped);
 
+/*
+ * bgzf analogue to hts_idx_amend_last.
+ *
+ * This is needed when multi-threading and writing indices on the fly.
+ * At the point of writing a record we know the virtual offset for start
+ * and end, but that end virtual offset may be the end of the current
+ * block.  In standard indexing our end virtual offset becomes the start
+ * of the next block.  Thus to ensure bit for bit compatibility we
+ * detect this boundary case and fix it up here.
+ */
+void bgzf_idx_amend_last(BGZF *fp, hts_idx_t *hidx, uint64_t offset);
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/sam.c b/sam.c
index ea66d25..0185b82 100644
--- a/sam.c
+++ b/sam.c
@@ -740,6 +740,8 @@ static int bam_write_idx1(htsFile *fp, const sam_hdr_t *h, const bam1_t *b) {
         return -1;
     if (!bfp->mt)
         hts_idx_amend_last(fp->idx, bgzf_tell(bfp));
+    else
+        bgzf_idx_amend_last(bfp, fp->idx, bgzf_tell(bfp));
 
     int ret = bam_write1(bfp, b);
     if (ret < 0)
-- 
2.25.1

